
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="./theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="./theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="./theme/font-awesome/css/font-awesome.min.css">

    <link href="./static/custom.css" rel="stylesheet">



    <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="author" content="Janos K. Divenyi" />
<meta name="description" content="Receiver Operating Characteristic curve is a great tool to visually illustrate the performance of a binary classifier. It plots the true positive rate (TPR) or the sensitivity against the false positive rate (FPR) or 1 - specificity. Usually, the algorithm gives you a probability (e.g. simple logistic regresssion), so for ..." />
<meta name="keywords" content="">
<meta property="og:site_name" content="Divenyi"/>
<meta property="og:title" content="Which binary classification model is better?"/>
<meta property="og:description" content="Receiver Operating Characteristic curve is a great tool to visually illustrate the performance of a binary classifier. It plots the true positive rate (TPR) or the sensitivity against the false positive rate (FPR) or 1 - specificity. Usually, the algorithm gives you a probability (e.g. simple logistic regresssion), so for ..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="./which-binary-classification-model-is-better.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2015-05-27 00:00:00+02:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="./author/janos-k-divenyi.html">
<meta property="article:section" content="blog"/>
<meta property="og:image" content="../images/divenyi_circle_small.png">

  <title>Divenyi &ndash; Which binary classification model is better?</title>

</head>
<body>
  <aside>
    <div>
      <a href=".">
        <img src="../images/divenyi_circle_small.png" alt="Janos K. Divenyi" title="Janos K. Divenyi">
      </a>
      <h1><a href=".">Janos K. Divenyi</a></h1>

<p>data scientist</p>
      <nav>
        <ul class="list">
          <li><a href="./pages/about-me.html#about-me">about&nbsp;me</a></li>
          <li><a href="./pages/research.html#research">research</a></li>
          <li><a href="./pages/teaching.html#teaching">teaching</a></li>

        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-linkedin" href="http://hu.linkedin.com/in/janosdivenyi" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-twitter" href="https://twitter.com/divenyijanos" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-github" href="https://github.com/divenyijanos" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-stack-overflow" href="https://stackoverflow.com/users/3409615/janosdivenyi" target="_blank"><i class="fa fa-stack-overflow"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>


<article class="single">
  <header>
    <h1 id="which-binary-classification-model-is-better">Which binary classification model is&nbsp;better?</h1>
    <p>
          Posted on Wed 27 May 2015 in <a href="./category/blog.html">blog</a>


        &#8226; 3 min read
    </p>
  </header>


  <div>
    <p><a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver Operating Characteristic curve</a> 
is a great tool to visually illustrate the performance of a binary classifier. 
It plots the true positive rate (<span class="caps">TPR</span>) or the sensitivity against the false 
positive rate (<span class="caps">FPR</span>) or 1 - specificity. Usually, the algorithm gives you a
probability (e.g. simple 
<a href="http://en.wikipedia.org/wiki/Logistic_regression">logistic regresssion</a>),
so for classification you need to choose a cutoff point. The <span class="caps">FPR</span>-<span class="caps">TPR</span> pairs for
different values of the cutoff gives you the <span class="caps">ROC</span> curve. Non-informative
algorithms lie on the 45-degree line, as they classify the same fraction of
positives and negatives as positives, that is <span class="math">\(TPR = TP/P = FP/N = FPR\)</span>.</p>
<p>But what if you want to compare two algorithms which give direct classification,
i.e. you have only two points in the plot? How to decide whether algorithm (2)
is better than algorithm&nbsp;(1)?</p>
<p><img src="../images/roc.png" width="60%" /></p>
<p>It is clear that algorithm (2) classifies more items as positive than algorithm
(1) and that this results in both more true positives (higher sensitivity) and
more false positives (lower specificity). Is this higher rate of positive
classification informative? What would we get if we just got labels negatively
classified by algorithm (1) and classified them randomly as positive? How would 
we move from algorithm (1) on the&nbsp;graph?</p>
<p>The original negative-labels are both true negatives and false negatives. A 
random classifier would classify them as positives in the same share. Let&#8217;s say
we are classifying an item as positive by probability <span class="math">\(\lambda\)</span>. Then, we are
going to have <span class="math">\(\lambda*TN\)</span> new false positives and <span class="math">\(\lambda*FN\)</span> new true
positives relative to algorithm (1). This results in the following measures for
the <span class="caps">ROC</span>&nbsp;curve:</p>
<div class="math">$$Sensitivity' = Sensitivity + \frac{\lambda*FN}{P} 
1 - Specificity' = 1 - Specificity + \frac{\lambda*TN}{N}$$</div>
<p>Thus, the slope of the movement is&nbsp;just</p>
<div class="math">$$\frac{\lambda*FN / P}{\lambda*TN / N} = \frac{1 - TP / P}{1 - TN / N} =
\frac{1 - Sensitivity}{Specificity}$$</div>
<p>It depends on <span class="math">\(\lambda\)</span> where we end up along this line. Therefore, it seems
that algorithm (2) not just randomly adds more positively-classified items but 
also contains some information relative to algorithm&nbsp;(1).</p>
<p><img src="../images/roc_random.png" width="60%" /></p>
<p>We can arrive to the same conclusion by less calculation as well. A possible
random classification is to classify each item as positive (<span class="math">\(\lambda = 1\)</span>). If
we take all the negatively-labeled item and classify them &#8220;randomly&#8221; as
positive, we end up having only positively classified items which leads to
extreme values of specificity (0) and sensitivity (1). To connect the point with
the (1, 1) point we should draw a line with slope <span class="math">\(\frac{1 -
Sensitivity}{Specificity}\)</span>.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>




<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'divenyijanos';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
        Please enable JavaScript to view comments.

</noscript>
</article>

    <footer>
<p>&copy; Janos K. Divenyi </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85196661-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Divenyi ",
  "url" : ".",
  "image": "../images/divenyi_circle_small.png",
  "description": ""
}
</script>
</body>
</html>